---
category: news
title: "Baidu details its adversarial toolbox for testing robustness of AI models"
excerpt: "No matter the claimed robustness of AI and machine learning systems in production, none are immune to adversarial attacks, or techniques that attempt to fool algorithms through malicious input. It’s been shown that generating even small perturbations on images can fool the best of classifiers with high probability. And that’s problematic ..."
publishedDateTime: 2020-01-17T22:56:00Z
sourceUrl: https://venturebeat.com/2020/01/17/baidu-details-its-adversarial-toolbox-for-testing-robustness-of-ai-models/
ampUrl: https://venturebeat.com/2020/01/17/baidu-details-its-adversarial-toolbox-for-testing-robustness-of-ai-models/amp/
cdnAmpUrl: https://venturebeat-com.cdn.ampproject.org/c/s/venturebeat.com/2020/01/17/baidu-details-its-adversarial-toolbox-for-testing-robustness-of-ai-models/amp/
type: article
quality: 86
heat: 86
published: true

provider:
  name: VentureBeat
  domain: venturebeat.com
  images:
    - url: /assets/images/organizations/venturebeat.com-50x50.jpg
      width: 50
      height: 50

topics:
  - AI

images:
  - url: https://venturebeat.com/wp-content/uploads/2016/06/Baidu-Silicon-Valley-AI-Lab-Novet-2-e1579301361248.jpg?fit=1200%2C600&strip=all
    width: 1200
    height: 600
    title: "Baidu details its adversarial toolbox for testing robustness of AI models"

secured: "X6eSNDZLQmNDa/SJa0ZSQ9UlvoRfjBn6dh0DShr+Z/eZ1wBCx2JgA9xM9o3EdAar7d+5gpNLWk7JasUpJ2QZ1gkETm2nOXe85UDvNQIv5SMgE9Ka4d9CqNi3sby3MRS2mkXDZtHj6s3z+tQo/lE2siNFW6s8bpdfwwftIENzqx6QLg9nHe9HsU1U2IbonLbJCoDvioQMlwGmqDNUDbMWFcWEnMXDWiWv8wvT1LVbYMpyFUqROQlMSyFEZcsZRbsMrzgwEq1LPq51ZcTCnfqPsThFuJ5oInJYNV+3jm1Xy1o=;gRBJm1vLaUweUFWKnCxX1Q=="
---

