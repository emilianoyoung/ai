---
category: news
title: "Content optimization using entities: An actionable guide"
excerpt: "BERT (Bidirectional Encoder Representations from Transformers) is a Natural Language Processing model that Google introduced in 2018 and began rolling out in October 2019. BERT has the ability to consider the full context of a word based on the words that come before or after named entities. We won’t dive deep, but we’ll look at an example ..."
publishedDateTime: 2019-12-24T14:33:00Z
sourceUrl: https://www.searchenginewatch.com/2019/12/24/content-optimization-using-entities/
ampUrl: https://www.searchenginewatch.com/2019/12/24/content-optimization-using-entities/amp/
cdnAmpUrl: https://www-searchenginewatch-com.cdn.ampproject.org/c/s/www.searchenginewatch.com/2019/12/24/content-optimization-using-entities/amp/
type: article
quality: 44
heat: 44
published: false

provider:
  name: Search Engine Watch
  domain: searchenginewatch.com

topics:
  - AI
  - Natural Language Processing

images:
  - url: https://www.bing.com/th?id=ON.6852875905E4632CF5B495ADE3C6E8CD
    width: 360
    height: 240
    title: "Content optimization using entities: An actionable guide"

secured: "nrCW79uYt/efkoQ3U26qJMNv1ZVELLmtnUyCCWCA/TbA8ebFgnwtmFT7FhktXhvChfDrQX5k4pz+FqVD1F0/9QdF36FGNaxH6oOTUIXYu5/T/wwOKWt5iu9EEA4inJDKaryCoOxql4ugJ4805giIQC2BlkT5A9W9XWhYtHK56bIPrV6+uM2dwdSIWnG2xqVWxjnNsVZ8xhKrDGatuiYio0TPA2BWsA1pnp27hfN6QnJq3XJb2P4864693fsoiLZDz6BT+7svOtswayXa8Oe4Hg==;ZLelti/V6WOc/NUwaO0vQw=="
---

